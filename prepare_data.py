"""
Chuáº©n bá»‹ dá»¯ liá»‡u cho YOLOv8 Classification vÃ  Detection
=========================================================
Script nÃ y xá»­ lÃ½ dá»¯ liá»‡u X-quang ngá»±c thÃ´ thÃ nh 2 dataset riÃªng biá»‡t:
1. dataset_cls: Cho YOLOv8-cls (4 lá»›p phÃ¢n loáº¡i)
2. dataset_det: Cho YOLOv8-det (2 lá»›p phÃ¡t hiá»‡n + background images)

TÃ¡c giáº£: AI4Life Team
NgÃ y: 2025
"""

import os
import shutil
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
import cv2
from tqdm import tqdm
import random
import yaml

# Seed cho reproducibility
random.seed(42)
np.random.seed(42)


class DataPreparer:
    """
    Lá»›p xá»­ lÃ½ vÃ  chuáº©n bá»‹ dá»¯ liá»‡u cho YOLOv8.
    
    Attributes:
        csv_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file CSV chá»©a metadata
        images_dir: ThÆ° má»¥c chá»©a áº£nh gá»‘c
        output_dir: ThÆ° má»¥c output chÃ­nh
        val_ratio: Tá»· lá»‡ validation (máº·c Ä‘á»‹nh 0.2 = 20%)
    """
    
    def __init__(self, csv_path: str, images_dir: str, output_dir: str, val_ratio: float = 0.2):
        self.csv_path = csv_path
        self.images_dir = images_dir
        self.output_dir = output_dir
        self.val_ratio = val_ratio
        
        # ThÆ° má»¥c output cho 2 dataset
        self.cls_dir = os.path.join(output_dir, 'dataset_cls')
        self.det_dir = os.path.join(output_dir, 'dataset_det')
        
        # Mapping lá»›p
        self.cls_classes = ['healthy', 'sick_but_no_tb', 'active_tb', 'latent_tb']
        self.det_classes = ['active_tb', 'latent_tb']  # Chá»‰ 2 lá»›p cho detection
        
        # Load data
        self.df = None
        
    def load_data(self):
        """Äá»c vÃ  phÃ¢n tÃ­ch file CSV"""
        print("ğŸ“– Äang Ä‘á»c file CSV...")
        self.df = pd.read_csv(self.csv_path)
        
        print(f"âœ… ÄÃ£ táº£i {len(self.df)} máº«u")
        print(f"\nğŸ“Š PhÃ¢n bá»‘ dá»¯ liá»‡u ban Ä‘áº§u:")
        
        # PhÃ¢n loáº¡i áº£nh theo class
        self.df['class_name'] = self.df.apply(self._get_class_name, axis=1)
        
        class_counts = self.df['class_name'].value_counts()
        for cls, count in class_counts.items():
            print(f"   {cls}: {count} áº£nh")
            
        return self.df
    
    def _get_class_name(self, row):
        """XÃ¡c Ä‘á»‹nh tÃªn lá»›p tá»« row data"""
        if row['image_type'] == 'healthy':
            return 'healthy'
        elif row['image_type'] == 'sick_but_no_tb':
            return 'sick_but_no_tb'
        elif row['target'] == 'tb':
            tb_type = row.get('tb_type', 'active_tb')
            if pd.notna(tb_type) and tb_type == 'latent_tb':
                return 'latent_tb'
            else:
                return 'active_tb'
        return 'healthy'  # Fallback
    
    def find_image_path(self, filename: str) -> str:
        """TÃ¬m Ä‘Æ°á»ng dáº«n thá»±c táº¿ cá»§a áº£nh"""
        possible_paths = [
            os.path.join(self.images_dir, filename),
            os.path.join(self.images_dir, 'train', filename),
            os.path.join(self.images_dir, 'val', filename),
            os.path.join(self.images_dir, 'test', filename),
            os.path.join(os.path.dirname(self.images_dir), 'test', filename),
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
        
        # TÃ¬m kiáº¿m Ä‘á»‡ quy
        base_dir = Path(self.images_dir).parent
        for root, dirs, files in os.walk(base_dir):
            if filename in files:
                return os.path.join(root, filename)
        
        return None
    
    # =========================================================================
    # OFFLINE AUGMENTATION CHO Lá»šP THIá»‚U Sá» (latent_tb)
    # =========================================================================
    
    def offline_augmentation(self, target_class: str = 'latent_tb', target_count: int = 800):
        """
        TÄƒng cÆ°á»ng dá»¯ liá»‡u OFFLINE cho lá»›p thiá»ƒu sá»‘.
        
        Ã tÆ°á»Ÿng: VÃ¬ latent_tb chá»‰ cÃ³ 239 áº£nh (ráº¥t Ã­t so vá»›i cÃ¡c lá»›p khÃ¡c),
        ta cáº§n táº¡o thÃªm áº£nh augmented TRÆ¯á»šC KHI chia train/val Ä‘á»ƒ:
        - CÃ¢n báº±ng dataset
        - GiÃºp model há»c Ä‘Æ°á»£c nhiá»u biáº¿n thá»ƒ hÆ¡n cá»§a lá»›p nÃ y
        
        Args:
            target_class: Lá»›p cáº§n augment (máº·c Ä‘á»‹nh: latent_tb)
            target_count: Sá»‘ lÆ°á»£ng áº£nh má»¥c tiÃªu sau augmentation
        """
        print(f"\nğŸ”„ Äang thá»±c hiá»‡n Offline Augmentation cho lá»›p '{target_class}'...")
        
        # Lá»c áº£nh cá»§a lá»›p cáº§n augment
        class_df = self.df[self.df['class_name'] == target_class].copy()
        current_count = len(class_df)
        
        if current_count >= target_count:
            print(f"   â„¹ï¸  Lá»›p {target_class} Ä‘Ã£ cÃ³ {current_count} áº£nh, khÃ´ng cáº§n augment")
            return
        
        # Sá»‘ áº£nh cáº§n táº¡o thÃªm
        needed = target_count - current_count
        print(f"   ğŸ“ˆ Cáº§n táº¡o thÃªm: {needed} áº£nh (hiá»‡n cÃ³: {current_count}, má»¥c tiÃªu: {target_count})")
        
        # Táº¡o thÆ° má»¥c táº¡m cho áº£nh augmented
        aug_dir = os.path.join(self.output_dir, 'augmented_temp', target_class)
        os.makedirs(aug_dir, exist_ok=True)
        
        # Danh sÃ¡ch áº£nh má»›i
        new_rows = []
        aug_count = 0
        
        while aug_count < needed:
            for idx, row in class_df.iterrows():
                if aug_count >= needed:
                    break
                    
                src_path = self.find_image_path(row['fname'])
                if src_path is None:
                    continue
                
                # Äá»c áº£nh
                img = cv2.imread(src_path)
                if img is None:
                    continue
                
                # Ãp dá»¥ng augmentation ngáº«u nhiÃªn
                aug_img, aug_type = self._apply_augmentation(img)
                
                # Táº¡o tÃªn file má»›i
                base_name = Path(row['fname']).stem
                ext = Path(row['fname']).suffix
                new_fname = f"{base_name}_aug_{aug_count}_{aug_type}{ext}"
                new_path = os.path.join(aug_dir, new_fname)
                
                # LÆ°u áº£nh augmented
                cv2.imwrite(new_path, aug_img)
                
                # Táº¡o row má»›i vá»›i thÃ´ng tin cáº­p nháº­t
                new_row = row.copy()
                new_row['fname'] = new_fname
                new_row['augmented'] = True
                new_row['aug_source'] = row['fname']
                new_row['aug_path'] = new_path
                
                # Cáº­p nháº­t bbox náº¿u cÃ³ flip
                if 'flip' in aug_type and pd.notna(row.get('bbox')) and row['bbox'] != 'none':
                    new_row['bbox'] = self._flip_bbox(row['bbox'], img.shape[1])
                
                new_rows.append(new_row)
                aug_count += 1
        
        # ThÃªm áº£nh augmented vÃ o dataframe
        if new_rows:
            aug_df = pd.DataFrame(new_rows)
            self.df = pd.concat([self.df, aug_df], ignore_index=True)
            
        print(f"   âœ… ÄÃ£ táº¡o {aug_count} áº£nh augmented cho lá»›p '{target_class}'")
        print(f"   ğŸ“Š Tá»•ng sá»‘ áº£nh lá»›p '{target_class}' sau augment: {len(self.df[self.df['class_name'] == target_class])}")
    
    def _apply_augmentation(self, img: np.ndarray) -> tuple:
        """
        Ãp dá»¥ng augmentation ngáº«u nhiÃªn cho áº£nh.
        
        CÃ¡c ká»¹ thuáº­t Ä‘Æ°á»£c chá»n phÃ¹ há»£p vá»›i áº£nh X-quang y táº¿:
        - Rotation nháº¹ (Â±15Â°): MÃ´ phá»ng gÃ³c chá»¥p khÃ¡c nhau
        - Brightness: MÃ´ phá»ng Ä‘iá»u kiá»‡n chá»¥p khÃ¡c nhau
        - Horizontal flip: Váº«n giá»¯ Ä‘áº·c Ä‘iá»ƒm y há»c
        - Contrast: TÄƒng/giáº£m Ä‘á»™ tÆ°Æ¡ng pháº£n
        
        Returns:
            tuple: (áº£nh augmented, loáº¡i augmentation)
        """
        aug_type = random.choice(['rotate', 'brightness', 'flip', 'contrast', 'combined'])
        
        if aug_type == 'rotate':
            # Xoay Â±15 Ä‘á»™
            angle = random.uniform(-15, 15)
            h, w = img.shape[:2]
            center = (w // 2, h // 2)
            matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            img = cv2.warpAffine(img, matrix, (w, h), borderMode=cv2.BORDER_REFLECT)
            
        elif aug_type == 'brightness':
            # Thay Ä‘á»•i Ä‘á»™ sÃ¡ng
            factor = random.uniform(0.7, 1.3)
            img = cv2.convertScaleAbs(img, alpha=factor, beta=0)
            
        elif aug_type == 'flip':
            # Láº­t ngang
            img = cv2.flip(img, 1)
            
        elif aug_type == 'contrast':
            # Thay Ä‘á»•i contrast
            factor = random.uniform(0.8, 1.2)
            mean = np.mean(img)
            img = cv2.convertScaleAbs(img, alpha=factor, beta=(1 - factor) * mean)
            
        elif aug_type == 'combined':
            # Káº¿t há»£p nhiá»u augmentation
            # Flip
            if random.random() > 0.5:
                img = cv2.flip(img, 1)
                aug_type = 'combined_flip'
            # Brightness
            factor = random.uniform(0.8, 1.2)
            img = cv2.convertScaleAbs(img, alpha=factor, beta=0)
            # Rotation nháº¹
            angle = random.uniform(-10, 10)
            h, w = img.shape[:2]
            center = (w // 2, h // 2)
            matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            img = cv2.warpAffine(img, matrix, (w, h), borderMode=cv2.BORDER_REFLECT)
        
        return img, aug_type
    
    def _flip_bbox(self, bbox_str: str, img_width: int) -> str:
        """Láº­t bbox theo chiá»u ngang khi flip áº£nh"""
        import ast
        try:
            bbox = ast.literal_eval(bbox_str)
            # TÃ­nh láº¡i xmin sau khi flip
            new_xmin = img_width - bbox['xmin'] - bbox['width']
            bbox['xmin'] = new_xmin
            return str(bbox)
        except:
            return bbox_str
    
    # =========================================================================
    # Táº O DATASET CHO CLASSIFICATION (dataset_cls)
    # =========================================================================
    
    def create_classification_dataset(self):
        """
        Táº¡o dataset cho YOLOv8-cls.
        
        Cáº¥u trÃºc output:
        dataset_cls/
        â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ healthy/
        â”‚   â”œâ”€â”€ sick_but_no_tb/
        â”‚   â”œâ”€â”€ active_tb/
        â”‚   â””â”€â”€ latent_tb/
        â””â”€â”€ val/
            â”œâ”€â”€ healthy/
            â”œâ”€â”€ sick_but_no_tb/
            â”œâ”€â”€ active_tb/
            â””â”€â”€ latent_tb/
        
        Logic:
        - Sá»­ dá»¥ng Táº¤T Cáº¢ áº£nh tá»« 4 lá»›p
        - Chia 80% train, 20% val (stratified)
        """
        print("\n" + "="*60)
        print("ğŸ“ Táº O DATASET CLASSIFICATION (4 Lá»šP)")
        print("="*60)
        
        # Táº¡o thÆ° má»¥c
        for split in ['train', 'val']:
            for cls in self.cls_classes:
                os.makedirs(os.path.join(self.cls_dir, split, cls), exist_ok=True)
        
        # Chia train/val theo stratified sampling
        train_df, val_df = train_test_split(
            self.df, 
            test_size=self.val_ratio,
            stratify=self.df['class_name'],
            random_state=42
        )
        
        print(f"\nğŸ“Š PhÃ¢n chia dá»¯ liá»‡u:")
        print(f"   Train: {len(train_df)} áº£nh")
        print(f"   Val: {len(val_df)} áº£nh")
        
        # Copy áº£nh vÃ o thÆ° má»¥c tÆ°Æ¡ng á»©ng
        stats = {'train': {cls: 0 for cls in self.cls_classes}, 
                 'val': {cls: 0 for cls in self.cls_classes}}
        
        for split, split_df in [('train', train_df), ('val', val_df)]:
            print(f"\nğŸ“¦ Äang xá»­ lÃ½ {split}...")
            for idx, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f"   {split}"):
                cls_name = row['class_name']
                
                # XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n nguá»“n
                if row.get('augmented', False) and pd.notna(row.get('aug_path')):
                    src_path = str(row['aug_path'])
                else:
                    src_path = self.find_image_path(str(row['fname']))
                
                if src_path and os.path.exists(src_path):
                    dst_path = os.path.join(self.cls_dir, split, cls_name, str(row['fname']))
                    shutil.copy2(src_path, dst_path)
                    stats[split][cls_name] += 1
        
        # In thá»‘ng kÃª
        print(f"\nâœ… Dataset Classification Ä‘Ã£ sáºµn sÃ ng!")
        print(f"ğŸ“ ÄÆ°á»ng dáº«n: {self.cls_dir}")
        print(f"\nğŸ“Š Thá»‘ng kÃª chi tiáº¿t:")
        for split in ['train', 'val']:
            print(f"\n   {split.upper()}:")
            for cls in self.cls_classes:
                print(f"      {cls}: {stats[split][cls]}")
        
        # Táº¡o file yaml config
        self._create_cls_yaml()
        
        return self.cls_dir
    
    def _create_cls_yaml(self):
        """Táº¡o file YAML config cho YOLOv8-cls"""
        yaml_content = {
            'path': os.path.abspath(self.cls_dir),
            'train': 'train',
            'val': 'val',
            'nc': 4,
            'names': self.cls_classes
        }
        
        yaml_path = os.path.join(self.cls_dir, 'dataset.yaml')
        with open(yaml_path, 'w') as f:
            yaml.dump(yaml_content, f, default_flow_style=False)
        
        print(f"\nğŸ“ File config: {yaml_path}")
    
    # =========================================================================
    # Táº O DATASET CHO DETECTION (dataset_det)
    # =========================================================================
    
    def create_detection_dataset(self, bg_samples_per_class: int = 500):
        """
        Táº¡o dataset cho YOLOv8-det.
        
        Cáº¥u trÃºc output:
        dataset_det/
        â”œâ”€â”€ images/
        â”‚   â”œâ”€â”€ train/
        â”‚   â””â”€â”€ val/
        â”œâ”€â”€ labels/
        â”‚   â”œâ”€â”€ train/
        â”‚   â””â”€â”€ val/
        â””â”€â”€ dataset.yaml
        
        Logic quan trá»ng:
        
        1. POSITIVE SAMPLES (cÃ³ bounding box):
           - active_tb: class_id = 0
           - latent_tb: class_id = 1
           - File label: chá»©a bbox theo format YOLO
        
        2. BACKGROUND IMAGES (khÃ´ng cÃ³ object):
           - healthy vÃ  sick_but_no_tb
           - Láº¥y máº«u má»™t sá»‘ lÆ°á»£ng nháº¥t Ä‘á»‹nh (máº·c Ä‘á»‹nh 500 má»—i lá»›p)
           - File label: Táº O FILE Rá»–NG (.txt trá»‘ng)
           
           âš ï¸ Táº I SAO Cáº¦N BACKGROUND IMAGES?
           - YOLO cáº§n há»c phÃ¢n biá»‡t "cÃ³ object" vs "khÃ´ng cÃ³ object"
           - Náº¿u chá»‰ train vá»›i áº£nh cÃ³ TB, model sáº½ cÃ³ xu hÆ°á»›ng 
             phÃ¡t hiá»‡n TB á»Ÿ má»i nÆ¡i (False Positive cao)
           - Background images dáº¡y model biáº¿t ráº±ng:
             "ÄÃ¢y lÃ  áº£nh KHÃ”NG cÃ³ tá»•n thÆ°Æ¡ng TB"
           - File .txt rá»—ng = khÃ´ng cÃ³ object trong áº£nh nÃ y
        
        Args:
            bg_samples_per_class: Sá»‘ áº£nh background láº¥y tá»« má»—i lá»›p (healthy, sick_but_no_tb)
        """
        print("\n" + "="*60)
        print("ğŸ“ Táº O DATASET DETECTION (2 Lá»šP + BACKGROUND)")
        print("="*60)
        
        # Táº¡o thÆ° má»¥c
        for folder in ['images', 'labels']:
            for split in ['train', 'val']:
                os.makedirs(os.path.join(self.det_dir, folder, split), exist_ok=True)
        
        # =====================================================================
        # BÆ¯á»šC 1: Xá»¬ LÃ POSITIVE SAMPLES (active_tb, latent_tb)
        # =====================================================================
        print("\nğŸ“Œ BÆ°á»›c 1: Xá»­ lÃ½ Positive Samples (cÃ³ bounding box)...")
        
        # Lá»c áº£nh cÃ³ bbox (active_tb vÃ  latent_tb)
        positive_df = self.df[self.df['class_name'].isin(['active_tb', 'latent_tb'])].copy()
        
        # Chia train/val
        pos_train, pos_val = train_test_split(
            positive_df,
            test_size=self.val_ratio,
            stratify=positive_df['class_name'],
            random_state=42
        )
        
        stats = {
            'train': {'active_tb': 0, 'latent_tb': 0, 'background': 0},
            'val': {'active_tb': 0, 'latent_tb': 0, 'background': 0}
        }
        
        # Xá»­ lÃ½ positive samples
        for split, split_df in [('train', pos_train), ('val', pos_val)]:
            print(f"\n   ğŸ“¦ Äang xá»­ lÃ½ {split} (positive)...")
            for idx, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f"      {split}"):
                success = self._process_positive_sample(row, split)
                if success:
                    stats[split][row['class_name']] += 1
        
        # =====================================================================
        # BÆ¯á»šC 2: Xá»¬ LÃ BACKGROUND IMAGES (healthy, sick_but_no_tb)
        # =====================================================================
        print(f"\nğŸ“Œ BÆ°á»›c 2: Xá»­ lÃ½ Background Images (khÃ´ng cÃ³ object)...")
        print(f"   â„¹ï¸  Láº¥y {bg_samples_per_class} áº£nh tá»« má»—i lá»›p: healthy, sick_but_no_tb")
        print(f"""
   âš ï¸  Táº I SAO Cáº¦N BACKGROUND IMAGES?
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   â€¢ YOLO cáº§n há»c phÃ¢n biá»‡t "cÃ³ object" vs "khÃ´ng cÃ³ object"
   â€¢ Náº¿u chá»‰ train vá»›i áº£nh cÃ³ TB â†’ False Positive cao!
   â€¢ Background images dáº¡y model: "áº¢nh nÃ y KHÃ”NG cÃ³ tá»•n thÆ°Æ¡ng TB"
   â€¢ File .txt rá»—ng = khÃ´ng cÃ³ object nÃ o trong áº£nh nÃ y
   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""")
        
        # Lá»c áº£nh khÃ´ng cÃ³ TB
        background_df = self.df[self.df['class_name'].isin(['healthy', 'sick_but_no_tb'])].copy()
        
        # Láº¥y máº«u tá»« má»—i lá»›p
        bg_samples = []
        for cls in ['healthy', 'sick_but_no_tb']:
            cls_df = background_df[background_df['class_name'] == cls]
            sample_size = min(bg_samples_per_class, len(cls_df))
            sampled = cls_df.sample(n=sample_size, random_state=42)
            bg_samples.append(sampled)
            print(f"   ÄÃ£ láº¥y {sample_size} áº£nh tá»« lá»›p '{cls}'")
        
        bg_df = pd.concat(bg_samples, ignore_index=True)
        
        # Chia train/val cho background
        bg_train, bg_val = train_test_split(
            bg_df,
            test_size=self.val_ratio,
            random_state=42
        )
        
        # Xá»­ lÃ½ background samples
        for split, split_df in [('train', bg_train), ('val', bg_val)]:
            print(f"\n   ğŸ“¦ Äang xá»­ lÃ½ {split} (background)...")
            for idx, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f"      {split}"):
                success = self._process_background_sample(row, split)
                if success:
                    stats[split]['background'] += 1
        
        # In thá»‘ng kÃª
        print(f"\nâœ… Dataset Detection Ä‘Ã£ sáºµn sÃ ng!")
        print(f"ğŸ“ ÄÆ°á»ng dáº«n: {self.det_dir}")
        print(f"\nğŸ“Š Thá»‘ng kÃª chi tiáº¿t:")
        for split in ['train', 'val']:
            print(f"\n   {split.upper()}:")
            print(f"      active_tb (class 0): {stats[split]['active_tb']}")
            print(f"      latent_tb (class 1): {stats[split]['latent_tb']}")
            print(f"      background (no object): {stats[split]['background']}")
            total = sum(stats[split].values())
            print(f"      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            print(f"      Tá»•ng: {total}")
        
        # Táº¡o file yaml config
        self._create_det_yaml()
        
        return self.det_dir
    
    def _process_positive_sample(self, row, split: str) -> bool:
        """
        Xá»­ lÃ½ má»™t áº£nh positive (cÃ³ bounding box).
        
        Args:
            row: DÃ²ng dá»¯ liá»‡u tá»« DataFrame
            split: 'train' hoáº·c 'val'
        
        Returns:
            bool: True náº¿u xá»­ lÃ½ thÃ nh cÃ´ng
        """
        import ast
        
        # XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n nguá»“n
        if row.get('augmented', False) and pd.notna(row.get('aug_path')):
            src_path = str(row['aug_path'])
        else:
            src_path = self.find_image_path(str(row['fname']))
        
        if not src_path or not os.path.exists(src_path):
            return False
        
        # Copy áº£nh
        dst_img = os.path.join(self.det_dir, 'images', split, str(row['fname']))
        shutil.copy2(src_path, dst_img)
        
        # Táº¡o file label
        label_fname = Path(str(row['fname'])).stem + '.txt'
        label_path = os.path.join(self.det_dir, 'labels', split, label_fname)
        
        # Parse bbox
        try:
            bbox_str = row.get('bbox', 'none')
            if pd.isna(bbox_str) or bbox_str == 'none':
                # Táº¡o file rá»—ng náº¿u khÃ´ng cÃ³ bbox
                open(label_path, 'w').close()
                return True
            
            bbox = ast.literal_eval(bbox_str)
            img_w = float(row['image_width'])
            img_h = float(row['image_height'])
            
            # Chuyá»ƒn sang format YOLO: class_id x_center y_center width height (normalized)
            x_center = (bbox['xmin'] + bbox['width'] / 2) / img_w
            y_center = (bbox['ymin'] + bbox['height'] / 2) / img_h
            width = bbox['width'] / img_w
            height = bbox['height'] / img_h
            
            # Clamp values
            x_center = max(0, min(1, x_center))
            y_center = max(0, min(1, y_center))
            width = max(0, min(1, width))
            height = max(0, min(1, height))
            
            # Class ID: 0 = active_tb, 1 = latent_tb
            class_id = 0 if row['class_name'] == 'active_tb' else 1
            
            with open(label_path, 'w') as f:
                f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
            
            return True
            
        except Exception as e:
            # Táº¡o file rá»—ng náº¿u lá»—i
            open(label_path, 'w').close()
            return True
    
    def _process_background_sample(self, row, split: str) -> bool:
        """
        Xá»­ lÃ½ má»™t áº£nh background (khÃ´ng cÃ³ object).
        
        QUAN TRá»ŒNG: Táº¡o file .txt Rá»–NG Ä‘á»ƒ YOLO biáº¿t ráº±ng
        áº£nh nÃ y khÃ´ng chá»©a object nÃ o.
        
        Args:
            row: DÃ²ng dá»¯ liá»‡u tá»« DataFrame
            split: 'train' hoáº·c 'val'
        
        Returns:
            bool: True náº¿u xá»­ lÃ½ thÃ nh cÃ´ng
        """
        src_path = self.find_image_path(row['fname'])
        
        if not src_path or not os.path.exists(src_path):
            return False
        
        # Copy áº£nh
        dst_img = os.path.join(self.det_dir, 'images', split, row['fname'])
        shutil.copy2(src_path, dst_img)
        
        # Táº O FILE LABEL Rá»–NG
        # âš ï¸ ÄÃ¢y lÃ  bÆ°á»›c quan trá»ng! File .txt rá»—ng cho YOLO biáº¿t
        # ráº±ng áº£nh nÃ y khÃ´ng chá»©a báº¥t ká»³ object nÃ o.
        label_fname = Path(str(row['fname'])).stem + '.txt'
        label_path = os.path.join(self.det_dir, 'labels', split, label_fname)
        
        # Táº¡o file rá»—ng
        open(label_path, 'w').close()
        
        return True
    
    def _create_det_yaml(self):
        """Táº¡o file YAML config cho YOLOv8-det"""
        yaml_content = {
            'path': os.path.abspath(self.det_dir),
            'train': 'images/train',
            'val': 'images/val',
            'nc': 2,
            'names': self.det_classes
        }
        
        yaml_path = os.path.join(self.det_dir, 'dataset.yaml')
        with open(yaml_path, 'w') as f:
            yaml.dump(yaml_content, f, default_flow_style=False)
        
        print(f"\nğŸ“ File config: {yaml_path}")
    
    # =========================================================================
    # CHáº Y TOÃ€N Bá»˜ PIPELINE
    # =========================================================================
    
    def run(self, augment_latent_tb: bool = True, latent_target: int = 800,
            bg_samples_per_class: int = 500):
        """
        Cháº¡y toÃ n bá»™ pipeline chuáº©n bá»‹ dá»¯ liá»‡u.
        
        Args:
            augment_latent_tb: CÃ³ augment lá»›p latent_tb khÃ´ng
            latent_target: Sá»‘ lÆ°á»£ng áº£nh má»¥c tiÃªu cho latent_tb sau augment
            bg_samples_per_class: Sá»‘ áº£nh background láº¥y tá»« má»—i lá»›p
        """
        print("\n" + "="*60)
        print("ğŸš€ Báº®T Äáº¦U CHUáº¨N Bá»Š Dá»® LIá»†U CHO YOLOv8")
        print("="*60)
        
        # 1. Load data
        self.load_data()
        
        # 2. Offline augmentation cho lá»›p thiá»ƒu sá»‘
        if augment_latent_tb:
            self.offline_augmentation('latent_tb', target_count=latent_target)
        
        # 3. Táº¡o dataset classification
        self.create_classification_dataset()
        
        # 4. Táº¡o dataset detection
        self.create_detection_dataset(bg_samples_per_class=bg_samples_per_class)
        
        # 5. In hÆ°á»›ng dáº«n training
        self._print_training_instructions()
        
        print("\n" + "="*60)
        print("âœ… HOÃ€N Táº¤T CHUáº¨N Bá»Š Dá»® LIá»†U!")
        print("="*60)
    
    def _print_training_instructions(self):
        """In hÆ°á»›ng dáº«n training"""
        print("\n" + "="*60)
        print("ğŸ“– HÆ¯á»šNG DáºªN TRAINING")
        print("="*60)
        
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  STAGE 1: CLASSIFICATION (4 Lá»šP)                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Command:                                                     â•‘
â•‘  yolo classify train \\                                       â•‘
â•‘      data={cls_dir} \\                                        â•‘
â•‘      model=yolov8n-cls.pt \\                                  â•‘
â•‘      epochs=100 \\                                            â•‘
â•‘      imgsz=224 \\                                             â•‘
â•‘      batch=32 \\                                              â•‘
â•‘      project=tb_classification                                â•‘
â•‘                                                               â•‘
â•‘  Hoáº·c dÃ¹ng Python:                                            â•‘
â•‘  from ultralytics import YOLO                                 â•‘
â•‘  model = YOLO('yolov8n-cls.pt')                              â•‘
â•‘  model.train(data='{cls_dir}', epochs=100, imgsz=224)        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  STAGE 2: DETECTION (2 Lá»šP + BACKGROUND)                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Command:                                                     â•‘
â•‘  yolo detect train \\                                         â•‘
â•‘      data={det_yaml} \\                                       â•‘
â•‘      model=yolov8n.pt \\                                      â•‘
â•‘      epochs=100 \\                                            â•‘
â•‘      imgsz=640 \\                                             â•‘
â•‘      batch=16 \\                                              â•‘
â•‘      project=tb_detection                                     â•‘
â•‘                                                               â•‘
â•‘  Hoáº·c dÃ¹ng Python:                                            â•‘
â•‘  from ultralytics import YOLO                                 â•‘
â•‘  model = YOLO('yolov8n.pt')                                  â•‘
â•‘  model.train(data='{det_yaml}', epochs=100, imgsz=640)       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""".format(
            cls_dir=self.cls_dir,
            det_yaml=os.path.join(self.det_dir, 'dataset.yaml')
        ))


# =============================================================================
# MAIN
# =============================================================================

def main():
    """HÃ m main Ä‘á»ƒ cháº¡y tá»« command line"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Chuáº©n bá»‹ dá»¯ liá»‡u cho YOLOv8 Classification vÃ  Detection',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥ sá»­ dá»¥ng:
  python prepare_data.py --csv data.csv --images ./images --output ./datasets
  python prepare_data.py --csv data.csv --images ./images --output ./datasets --no-augment
  python prepare_data.py --csv data.csv --images ./images --output ./datasets --bg-samples 800
        """
    )
    
    parser.add_argument('--csv', type=str, required=True,
                        help='ÄÆ°á»ng dáº«n Ä‘áº¿n file CSV chá»©a metadata')
    parser.add_argument('--images', type=str, required=True,
                        help='ThÆ° má»¥c chá»©a áº£nh gá»‘c')
    parser.add_argument('--output', type=str, default='./datasets',
                        help='ThÆ° má»¥c output (máº·c Ä‘á»‹nh: ./datasets)')
    parser.add_argument('--val-ratio', type=float, default=0.2,
                        help='Tá»· lá»‡ validation (máº·c Ä‘á»‹nh: 0.2)')
    parser.add_argument('--no-augment', action='store_true',
                        help='KhÃ´ng thá»±c hiá»‡n offline augmentation')
    parser.add_argument('--latent-target', type=int, default=800,
                        help='Sá»‘ lÆ°á»£ng áº£nh má»¥c tiÃªu cho latent_tb sau augment (máº·c Ä‘á»‹nh: 800)')
    parser.add_argument('--bg-samples', type=int, default=500,
                        help='Sá»‘ áº£nh background láº¥y tá»« má»—i lá»›p (máº·c Ä‘á»‹nh: 500)')
    
    args = parser.parse_args()
    
    # Cháº¡y pipeline
    preparer = DataPreparer(
        csv_path=args.csv,
        images_dir=args.images,
        output_dir=args.output,
        val_ratio=args.val_ratio
    )
    
    preparer.run(
        augment_latent_tb=not args.no_augment,
        latent_target=args.latent_target,
        bg_samples_per_class=args.bg_samples
    )


if __name__ == '__main__':
    main()
