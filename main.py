"""
Äiá»ƒm VÃ o ChÃ­nh - Há»‡ Thá»‘ng Cháº©n ÄoÃ¡n Bá»‡nh Lao Phá»•i (TB)

Script nÃ y cung cáº¥p CLI thá»‘ng nháº¥t cho toÃ n bá»™ pipeline cháº©n Ä‘oÃ¡n TB:
- Tiá»n xá»­ lÃ½ dá»¯ liá»‡u cho cáº£ phÃ¢n loáº¡i vÃ  phÃ¡t hiá»‡n
- Huáº¥n luyá»‡n model (phÃ¢n loáº¡i vÃ  phÃ¡t hiá»‡n)
- Suy luáº­n sá»­ dá»¥ng Kiáº¿n TrÃºc Cascade 2 Giai Äoáº¡n
- ÄÃ¡nh giÃ¡ vÃ  trá»±c quan hÃ³a

Kiáº¿n trÃºc: Clean Architecture vá»›i dependency injection
"""

import argparse
import sys
import os
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent))

# Import from src packages
from src.data import TBDataPreprocessor
from src.training import TBModelTrainer
from src.evaluation import TBModelEvaluator, TBHeatmapGenerator


def run_inference(args):
    """
    Cháº¡y pipeline suy luáº­n Cascade 2 Giai Äoáº¡n.
    Sá»­ dá»¥ng Clean Architecture vá»›i cÃ¡c adapter YOLOv8.
    """
    from src.infrastructure import (
        YOLOv8Classifier,
        YOLOv8Detector,
        OpenCVImageLoader,
        TBAnnotator
    )
    from src.usecases import TBDiagnosisUseCase, DiagnosisResultExporter
    
    print("\n" + "=" * 50)
    print("ğŸ©º CHáº¨N ÄOÃN LPHAU PHá»”I - SUY LUáº¬N CASCADE 2 GIAI ÄOáº N")
    print("=" * 50)
    
    # Khá»Ÿi táº¡o cÃ¡c thÃ nh pháº§n háº¡ táº§ng (Dependency Injection)
    print("\nğŸ“¦ Äang táº£i cÃ¡c model...")
    
    try:
        classifier = YOLOv8Classifier(model_path=Path(args.cls_model))
        detector = YOLOv8Detector(model_path=Path(args.det_model))
        image_loader = OpenCVImageLoader()
        annotator = TBAnnotator()
    except FileNotFoundError as e:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y model: {e}")
        print("   Vui lÃ²ng huáº¥n luyá»‡n cáº£ hai model phÃ¢n loáº¡i vÃ  phÃ¡t hiá»‡n trÆ°á»›c.")
        return
    except Exception as e:
        print(f"âŒ KhÃ´ng thá»ƒ táº£i model: {e}")
        return
    
    # Khá»Ÿi táº¡o use case vá»›i cÃ¡c dependency Ä‘Ã£ tiÃªm
    diagnosis_service = TBDiagnosisUseCase(
        classifier=classifier,
        detector=detector,
        image_loader=image_loader,
        annotator=annotator
    )
    
    # Cháº¡y suy luáº­n
    image_path = args.image
    print(f"\nğŸ” Äang xá»­ lÃ½: {image_path}")
    
    try:
        result = diagnosis_service.diagnose(
            image_path=image_path,
            detection_conf_threshold=args.conf,
            include_annotated_image=args.save_annotated,
            include_probabilities=True
        )
        
        # In tÃ³m táº¯t
        summary = DiagnosisResultExporter.to_summary(result)
        print(summary)
        
        # LÆ°u output JSON
        if args.output_json:
            DiagnosisResultExporter.to_json_file(result, args.output_json)
        
        # LÆ°u áº£nh Ä‘Ã£ chÃº thÃ­ch
        if args.save_annotated and result.annotated_image_base64:
            import base64
            output_path = f"annotated_{Path(image_path).name}"
            with open(output_path, 'wb') as f:
                f.write(base64.b64decode(result.annotated_image_base64))
            print(f"âœ… áº¢nh chÃº thÃ­ch Ä‘Ã£ lÆ°u: {output_path}")
            
    except Exception as e:
        print(f"âŒ Suy luáº­n tháº¥t báº¡i: {e}")
        import traceback
        traceback.print_exc()


def main():
    parser = argparse.ArgumentParser(
        description='Há»‡ Thá»‘ng Cháº©n ÄoÃ¡n TB - Pipeline Huáº¥n Luyá»‡n & Suy Luáº­n',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
VÃ­ dá»¥:
  # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u cho huáº¥n luyá»‡n
  python main.py --mode preprocess --csv data.csv --images images/ --output dataset/

  # Huáº¥n luyá»‡n model phÃ¢n loáº¡i
  python main.py --mode train-cls --output dataset/ --epochs 100

  # Huáº¥n luyá»‡n model phÃ¡t hiá»‡n
  python main.py --mode train-det --output dataset/ --epochs 100

  # Cháº¡y suy luáº­n trÃªn má»™t áº£nh
  python main.py --mode inference --image test.png --cls-model cls_best.pt --det-model det_best.pt

  # ÄÃ¡nh giÃ¡ model
  python main.py --mode evaluate --model best.pt --output dataset/
        """
    )
    
    parser.add_argument('--mode', type=str, required=True,
                       choices=['preprocess', 'train', 'train-cls', 'train-det', 
                               'evaluate', 'heatmap', 'inference', 'all'],
                       help='Cháº¿ Ä‘á»™ hoáº¡t Ä‘á»™ng')
    
    # CÃ¡c tham sá»‘ dá»¯ liá»‡u
    parser.add_argument('--csv', type=str, default='data.csv',
                       help='ÄÆ°á»ng dáº«n Ä‘áº¿n file data.csv')
    parser.add_argument('--images', type=str, default='images',
                       help='ThÆ° má»¥c chá»©a áº£nh')
    parser.add_argument('--output', type=str, default='tbx11k-simplified',
                       help='ThÆ° má»¥c Ä‘áº§u ra')
    
    # CÃ¡c tham sá»‘ model
    parser.add_argument('--model', type=str, default='best.pt',
                       help='ÄÆ°á»ng dáº«n model cho Ä‘Ã¡nh giÃ¡/heatmap')
    parser.add_argument('--cls-model', type=str, default='cls_best.pt',
                       help='ÄÆ°á»ng dáº«n model phÃ¢n loáº¡i (cho suy luáº­n)')
    parser.add_argument('--det-model', type=str, default='det_best.pt',
                       help='ÄÆ°á»ng dáº«n model phÃ¡t hiá»‡n (cho suy luáº­n)')
    
    # CÃ¡c tham sá»‘ huáº¥n luyá»‡n
    parser.add_argument('--epochs', type=int, default=100,
                       help='Sá»‘ epochs huáº¥n luyá»‡n')
    parser.add_argument('--batch', type=int, default=16,
                       help='KÃ­ch thÆ°á»›c batch')
    parser.add_argument('--img-size', type=int, default=512,
                       help='KÃ­ch thÆ°á»›c áº£nh')
    
    # CÃ¡c tham sá»‘ suy luáº­n
    parser.add_argument('--image', type=str, default=None,
                       help='ÄÆ°á»ng dáº«n áº£nh cho suy luáº­n')
    parser.add_argument('--conf', type=float, default=0.25,
                       help='NgÆ°á»¡ng tin cáº­y cho phÃ¡t hiá»‡n')
    parser.add_argument('--output-json', type=str, default=None,
                       help='ÄÆ°á»ng dáº«n file JSON Ä‘áº§u ra')
    parser.add_argument('--save-annotated', action='store_true',
                       help='LÆ°u áº£nh Ä‘Ã£ chÃº thÃ­ch')
    
    args = parser.parse_args()
    
    # Xá»­ lÃ½ cháº¿ Ä‘á»™ suy luáº­n
    if args.mode == 'inference':
        if not args.image:
            print("âŒ Lá»—i: --image lÃ  báº¯t buá»™c cho cháº¿ Ä‘á»™ suy luáº­n")
            return
        run_inference(args)
        return
    
    # Cháº¿ Ä‘á»™ tiá»n xá»­ lÃ½
    if args.mode == 'preprocess' or args.mode == 'all':
        print("\nğŸ”„ BÆ¯á»šC 1: TIá»€N Xá»¬ LÃ")
        print("   Táº¡o dataset cho cáº£ PhÃ¢n loáº¡i vÃ  PhÃ¡t hiá»‡n...")
        preprocessor = TBDataPreprocessor(args.csv, args.images, args.output)
        yaml_path = preprocessor.run()
    
    # Huáº¥n luyá»‡n model PhÃ¢n loáº¡i (YOLOv8-cls)
    if args.mode == 'train-cls':
        print("\nğŸ”„ HUáº¤N LUYá»†N: MODEL PHÃ‚N LOáº I (YOLOv8-cls)")
        from ultralytics import YOLO
        
        # YOLOv8-cls yÃªu cáº§u cáº¥u trÃºc thÆ° má»¥c: train/tÃªn_lá»›p/cÃ¡c_áº£nh
        cls_data_path = f"{args.output}/classification"
        if not os.path.exists(cls_data_path):
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y dataset phÃ¢n loáº¡i: {cls_data_path}")
            print("   Cháº¡y --mode preprocess trÆ°á»›c Ä‘á»ƒ táº¡o dataset.")
            return
            
        model = YOLO('yolov8n-cls.pt')
        results = model.train(
            data=cls_data_path,
            epochs=args.epochs,
            imgsz=args.img_size,
            batch=args.batch,
            project='tb_classification',
            name='yolov8n_cls',
            exist_ok=True,
            patience=20,
            save=True,
            plots=True,
            verbose=True
        )
        print(f"\nâœ… Model phÃ¢n loáº¡i Ä‘Ã£ lÆ°u vÃ o: {results.save_dir}/weights/best.pt")
    
    # Huáº¥n luyá»‡n model PhÃ¡t hiá»‡n (YOLOv8-det)
    if args.mode == 'train-det' or args.mode == 'train':
        print("\nğŸ”„ HUáº¤N LUYá»†N: MODEL PHÃT HIá»†N (YOLOv8)")
        yaml_path = f"{args.output}/detection/dataset.yaml"
        if not os.path.exists(yaml_path):
            yaml_path = f"{args.output}/dataset.yaml"
            
        if not os.path.exists(yaml_path):
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y dataset phÃ¡t hiá»‡n: {yaml_path}")
            print("   Cháº¡y --mode preprocess trÆ°á»›c Ä‘á»ƒ táº¡o dataset.")
            return
            
        trainer = TBModelTrainer(yaml_path, model_size='n')
        results = trainer.train(
            epochs=args.epochs, 
            batch_size=args.batch,
            img_size=args.img_size
        )
        print(f"\nâœ… Model phÃ¡t hiá»‡n Ä‘Ã£ lÆ°u vÃ o: {results.save_dir}/weights/best.pt")
    
    # Huáº¥n luyá»‡n cáº£ hai model tuáº§n tá»±
    if args.mode == 'all':
        print("\nğŸ”„ BÆ¯á»šC 2: HUáº¤N LUYá»†N MODEL PHÃ‚N LOáº I")
        # Sáº½ gá»i logic train-cls á»Ÿ Ä‘Ã¢y
        
        print("\nğŸ”„ BÆ¯á»šC 3: HUáº¤N LUYá»†N MODEL PHÃT HIá»†N")
        yaml_path = f"{args.output}/dataset.yaml"
        if os.path.exists(yaml_path):
            trainer = TBModelTrainer(yaml_path, model_size='n')
            results = trainer.train(
                epochs=args.epochs, 
                batch_size=args.batch,
                img_size=args.img_size
            )
            print(f"\nâœ… Model phÃ¡t hiá»‡n Ä‘Ã£ lÆ°u vÃ o: {results.save_dir}/weights/best.pt")
    
    # Cháº¿ Ä‘á»™ Ä‘Ã¡nh giÃ¡
    if args.mode == 'evaluate':
        print("\nğŸ”„ ÄÃNH GIÃ")
        yaml_path = f"{args.output}/dataset.yaml"
        evaluator = TBModelEvaluator(args.model)
        evaluator.evaluate_on_validation(yaml_path)
    
    # Cháº¿ Ä‘á»™ táº¡o heatmap
    if args.mode == 'heatmap':
        print("\nğŸ”„ Táº O HEATMAP")
        generator = TBHeatmapGenerator(args.model)
        generator.generate_batch_heatmaps('test', 'test_heatmaps')


if __name__ == '__main__':
    main()